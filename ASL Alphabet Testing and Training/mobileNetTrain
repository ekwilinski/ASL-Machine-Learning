from torchvision.transforms import transforms
from torch.utils.data import DataLoader
import pandas as pd
from torchvision.io import read_image
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset
from torchvision import datasets
from torchvision.transforms import ToTensor
from torchvision.models import mobilenet_v2
import matplotlib.pyplot as plt
from torch.optim import Adam
from torch.autograd import Variable
import torch
import matplotlib.pyplot as plt
import numpy as np
import torchvision

# Function to show the images
def imageshow(img):
    img = img / 2 + 0.5     # unnormalize
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()


# Function to test the model with a batch of images and show the labels predictions
def testBatch():
    # get batch of images from the test DataLoader  
    images, labels = next(iter(test_loader))
    images, labels = images.cuda(), labels.cuda()

    # show all images as one image grid
    imageshow(torchvision.utils.make_grid(images))
   
    # Show the real labels on the screen 
    print('Real labels: ', ' '.join('%5s' % classes[labels[j]] 
                               for j in range(batch_size)))
  
    # Let's see what if the model identifiers the  labels of those example
    outputs = model(images)
    
    # We got the probability for every 10 labels. The highest (max) probability should be correct label
    _, predicted = torch.max(outputs, 1)
    
    # Let's show the predicted labels on the screen to compare with the real ones
    print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] 
                              for j in range(batch_size)))

# Function to save the model
def saveModel():
    path = "./MobileASL.pth"
    torch.save(model.state_dict(), path)

    # Function to test the model with the test dataset and print the accuracy for the test images
def testAccuracy():
    
    model.eval()
    accuracy = 0.0
    total = 0.0
    
    with torch.no_grad():
        for data in test_loader:
            images, labels = data
            images, labels = images.cuda(), labels.cuda()
            # run the model on the test set to predict labels
            outputs = model(images)
            # the label with the highest energy will be our prediction
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            accuracy += (predicted == labels).sum().item()
    
    # compute the accuracy over all test images
    accuracy = (100 * accuracy / total)
    return(accuracy)


# Training function. We simply have to loop over our data iterator and feed the inputs to the network and optimize.
def train(num_epochs):
    
    best_accuracy = 0.0

    # Define your execution device
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    #device = torch.device("cpu") 
    print("The model will be running on", device, "device")
    # Convert model parameters and buffers to CPU or Cuda
    model.to(device)

    for epoch in range(num_epochs):  # loop over the dataset multiple times
        running_loss = 0.0
        running_acc = 0.0

        for i, (images, labels) in enumerate(train_loader, 0):
            
            # get the inputs
            images = Variable(images.to(device))
            labels = Variable(labels.to(device))

            # zero the parameter gradients
            optimizer.zero_grad()
            # predict classes using images from the training set
            outputs = model(images)
            # compute the loss based on model output and real labels
            loss = loss_fn(outputs, labels)
            # backpropagate the loss
            loss.backward()
            # adjust parameters based on the calculated gradients
            optimizer.step()

            # Let's print statistics for every 1,000 images
            running_loss += loss.item()     # extract the loss value
            if i % 347 == 346:    
                # print every 1000 (twice per epoch) 
                print('[%d, %5d] loss: %.3f' %
                      (epoch + 1, i + 1, running_loss / 347))
                # zero the loss
                running_loss = 0.0

        # Compute and print the average accuracy fo this epoch when tested over all 10000 test images
        accuracy = testAccuracy()
        print('For epoch', epoch+1,'the test accuracy over the whole test set is %d %%' % (accuracy))
        
        # we want to save the model if the accuracy is the best
        if accuracy > best_accuracy:
            saveModel()
            best_accuracy = accuracy


batch_size = 64
number_of_labels = 37
requires_grad = True
# Loading and normalizing the data.
# Define transformations for the training and test sets
transformations = transforms.Compose([
    #transforms.ToPILImage(),
    #transforms.RandomCrop(200, pad_if_needed=True),
    #transforms.RandomHorizontalFlip,
    transforms.RandomRotation(90),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                            std=[0.229, 0.224, 0.225])
])

#load custom datasets
training_data = datasets.ImageFolder("C:\\Users\\Elliot Kwilinski\\Downloads\\archive(6)\\Gesture Image Data", transform=transformations)
#test_data = datasets.ImageFolder("C:\\Users\\Elliot Kwilinski\\Downloads\\archive(4)", transform=transformations)
# Random split
train_set_size = int(len(training_data) * 0.8)
valid_set_size = len(training_data) - train_set_size
train_set, valid_set = torch.utils.data.random_split(training_data, [train_set_size, valid_set_size])

train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True)
dataiter = iter(train_loader)
images, labels = dataiter.next()
images, labels = images.cuda(), labels.cuda()
#print(labels)
#print(images.shape)
#print(labels.shape)
print("The number of images in a training set is: ", len(train_loader)*batch_size)
print("The number of batches per epoch is: ", len(train_loader))
classes = training_data.classes
# Set up Model
model = mobilenet_v2(pretrained=True)
model.classifier[1] = torch.nn.Linear(in_features=model.classifier[1].in_features, out_features=37)
model.cuda()
loss_fn = nn.CrossEntropyLoss()
optimizer = Adam(model.parameters(), lr=.0001)

if __name__ == "__main__":
    
    # Let's build our model
    train(11)
    print('Finished Training')

    # Test which classes performed well
    testAccuracy()
    
    # Let's load the model we just created and test the accuracy per label
    model = mobilenet_v2(pretrained=True)
    model.classifier[1] = torch.nn.Linear(in_features=model.classifier[1].in_features, out_features=37)
    print(model.classifier)
    if torch.cuda.is_available():
        model.cuda()
    path = "MobileASL.pth"
    model.load_state_dict(torch.load(path))

    # Test with batch of images
    testBatch()